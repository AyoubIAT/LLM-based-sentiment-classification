{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\\\Users\\\\boufo\\\\Start\\\\2A\\\\P2\\\\CSC_4MI01_TA\\\\projet3\\\\data\\\\training.1600000.processed.noemoticon.csv\"\n",
    "column_names = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "data = pd.read_csv(file_path, encoding=\"latin1\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target         ids                          date      flag  \\\n",
      "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
      "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
      "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
      "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
      "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
      "\n",
      "              user                                               text  \n",
      "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
      "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
      "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
      "4           Karoli  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['target', 'ids', 'date', 'flag', 'user', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...       0\n",
      "1  is upset that he can't update his Facebook by ...       0\n",
      "2  @Kenichan I dived many times for the ball. Man...       0\n",
      "3    my whole body feels itchy and like its on fire        0\n",
      "4  @nationwideclass no, it's not behaving at all....       0\n"
     ]
    }
   ],
   "source": [
    "data = data[['text', 'target']]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text      0\n",
      "target    0\n",
      "dtype: int64\n",
      "target\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "print(data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : handle metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove mentions (@username), URLs, and special characters\n",
    "    text = re.sub(r'@[\\w]*', '', text)  # Remove mentions\n",
    "    text = re.sub(r'https?://\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabet characters\n",
    "    return text.lower()  # Convert to lowercase\n",
    "\n",
    "# Apply cleaning to the text column\n",
    "data['clean_text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean data\n",
    "data.to_pickle(\"cleaned_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>awww thats a bummer  you shoulda got david ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "      <td>i dived many times for the ball managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "      <td>no its not behaving at all im mad why am i he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...       0   \n",
       "1  is upset that he can't update his Facebook by ...       0   \n",
       "2  @Kenichan I dived many times for the ball. Man...       0   \n",
       "3    my whole body feels itchy and like its on fire        0   \n",
       "4  @nationwideclass no, it's not behaving at all....       0   \n",
       "\n",
       "                                          clean_text  \n",
       "0     awww thats a bummer  you shoulda got david ...  \n",
       "1  is upset that he cant update his facebook by t...  \n",
       "2   i dived many times for the ball managed to sa...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4   no its not behaving at all im mad why am i he...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          0\n",
      "target        0\n",
      "clean_text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = \"cuda\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 50000/50000 [20:31<00:00, 40.58it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings_batch(texts):\n",
    "    # Tokenize the input texts in a batch\n",
    "    inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Batch of sentence embeddings\n",
    "    \n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "# Process data in batches\n",
    "batch_size = 32\n",
    "embeddings = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size), desc=\"Processing Batches\"):\n",
    "    batch_texts = data['clean_text'][i:i + batch_size].tolist()\n",
    "    embeddings_batch = get_embeddings_batch(batch_texts)\n",
    "    embeddings.extend(embeddings_batch)\n",
    "\n",
    "# Add embeddings back to the DataFrame\n",
    "data['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data['embedding'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding\n",
      "768    1600000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "embedding_lengths = data['embedding'].apply(lambda x: len(x) if x is not None else None)\n",
    "print(embedding_lengths.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "data.to_pickle(\"data_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML Models on LLM Embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
